{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55f7f49-b7eb-4f8e-b856-a7c38f8eb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve)\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5839d2-31d6-4c57-87bc-5c6000ebd249",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ab7c4d-f789-498e-acd9-082cea3530dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(permutation_folder, target_column='Outcome', random_state=42):\n",
    "    \"\"\"\n",
    "    Train a Logistic Regression classifier on a permutation dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - permutation_folder: path to the permutation folder containing train/validation/test CSVs\n",
    "    - target_column: name of the target column (default: 'Outcome')\n",
    "    - random_state: random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - model: trained LogisticRegression model\n",
    "    - scaler: fitted StandardScaler\n",
    "    - results: dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading data from: {permutation_folder}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load the datasets\n",
    "    train_df = pd.read_csv(os.path.join(permutation_folder, 'train.csv'))\n",
    "    val_df = pd.read_csv(os.path.join(permutation_folder, 'validation.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(permutation_folder, 'test.csv'))\n",
    "    \n",
    "    print(f\"Train set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X_train = train_df.drop(columns=[target_column])\n",
    "    X_train = X_train.drop(columns=['diabetes_stage'])\n",
    "    y_train = train_df[target_column]\n",
    "    \n",
    "    X_val = val_df.drop(columns=[target_column])\n",
    "    X_val = X_val.drop(columns=['diabetes_stage'])\n",
    "    y_val = val_df[target_column]\n",
    "    \n",
    "    X_test = test_df.drop(columns=[target_column])\n",
    "    X_test = X_test.drop(columns=['diabetes_stage'])\n",
    "    y_test = test_df[target_column]\n",
    "\n",
    "    # Handle categorical variables\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if categorical_cols:\n",
    "        print(f\"\\nCategorical columns found: {categorical_cols}\")\n",
    "        print(\"Applying one-hot encoding...\")\n",
    "        \n",
    "        X_train = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "        X_val = pd.get_dummies(X_val, columns=categorical_cols, drop_first=True)\n",
    "        X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    # Align columns across all sets\n",
    "    X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "    \n",
    "    print(f\"\\nFeatures: {list(X_train.columns)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    # Standardize features\n",
    "    print(\"\\nStandardizing features...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    print(\"\\nTraining Logistic Regression model...\")\n",
    "    model = LogisticRegression(random_state=random_state, max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Get prediction probabilities for ROC curve\n",
    "    y_train_proba = model.predict_proba(X_train_scaled)[:, 1]\n",
    "    y_val_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results = {}\n",
    "    for split_name, y_true, y_pred, y_proba in [\n",
    "        ('train', y_train, y_train_pred, y_train_proba),\n",
    "        ('validation', y_val, y_val_pred, y_val_proba),\n",
    "        ('test', y_test, y_test_pred, y_test_proba)\n",
    "    ]:\n",
    "        results[split_name] = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "            'roc_auc': roc_auc_score(y_true, y_proba),\n",
    "            'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'y_proba': y_proba\n",
    "        }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for split_name in ['train', 'validation', 'test']:\n",
    "        print(f\"\\n{split_name.upper()} SET:\")\n",
    "        print(f\"  Accuracy:  {results[split_name]['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {results[split_name]['precision']:.4f}\")\n",
    "        print(f\"  Recall:    {results[split_name]['recall']:.4f}\")\n",
    "        print(f\"  F1-Score:  {results[split_name]['f1']:.4f}\")\n",
    "        print(f\"  ROC-AUC:   {results[split_name]['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Generate visualizations\n",
    "    output_dir = '../results/LogisticRegression/'\n",
    "    plot_results(results, model, X_train.columns, output_dir)\n",
    "    \n",
    "    # Save model metrics to file\n",
    "    save_metrics(results, output_dir)\n",
    "    \n",
    "    return model, scaler, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508416ca-df57-4a73-a659-0ae86431e191",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac445fb4-3960-41a2-8128-842bced9aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, model, feature_names, output_dir):\n",
    "    \"\"\"Generate and save visualization plots.\"\"\"\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # 1. Confusion Matrices\n",
    "    for idx, split_name in enumerate(['train', 'validation', 'test'], 1):\n",
    "        ax = plt.subplot(3, 3, idx)\n",
    "        cm = results[split_name]['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "        ax.set_title(f'{split_name.capitalize()} Confusion Matrix', fontweight='bold')\n",
    "        ax.set_ylabel('True Label')\n",
    "        ax.set_xlabel('Predicted Label')\n",
    "    \n",
    "    # 2. Metrics Comparison Bar Chart\n",
    "    ax = plt.subplot(3, 3, 4)\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.25\n",
    "    \n",
    "    train_scores = [results['train'][m] for m in metrics]\n",
    "    val_scores = [results['validation'][m] for m in metrics]\n",
    "    test_scores = [results['test'][m] for m in metrics]\n",
    "    \n",
    "    ax.bar(x - width, train_scores, width, label='Train', alpha=0.8)\n",
    "    ax.bar(x, val_scores, width, label='Validation', alpha=0.8)\n",
    "    ax.bar(x + width, test_scores, width, label='Test', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Metrics Comparison', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([m.replace('_', ' ').title() for m in metrics], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 3. ROC Curves\n",
    "    ax = plt.subplot(3, 3, 5)\n",
    "    for split_name, color in [('train', 'blue'), ('validation', 'orange'), ('test', 'green')]:\n",
    "        fpr, tpr, _ = roc_curve(results[split_name]['y_true'], results[split_name]['y_proba'])\n",
    "        auc = results[split_name]['roc_auc']\n",
    "        ax.plot(fpr, tpr, label=f'{split_name.capitalize()} (AUC={auc:.3f})', color=color, linewidth=2)\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curves', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Feature Importance (Coefficients)\n",
    "    ax = plt.subplot(3, 3, 6)\n",
    "    coefficients = model.coef_[0]\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': coefficients,\n",
    "        'Abs_Coefficient': np.abs(coefficients)\n",
    "    }).sort_values('Abs_Coefficient', ascending=True)\n",
    "    \n",
    "    colors = ['red' if c < 0 else 'green' for c in feature_importance['Coefficient']]\n",
    "    ax.barh(range(len(feature_importance)), feature_importance['Coefficient'], color=colors, alpha=0.7)\n",
    "    ax.set_yticks(range(len(feature_importance)))\n",
    "    ax.set_yticklabels(feature_importance['Feature'])\n",
    "    ax.set_xlabel('Coefficient Value')\n",
    "    ax.set_title('Feature Importance (Coefficients)', fontweight='bold')\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # 5. Prediction Distribution\n",
    "    for idx, split_name in enumerate(['train', 'validation', 'test'], 7):\n",
    "        ax = plt.subplot(3, 3, idx)\n",
    "        y_proba = results[split_name]['y_proba']\n",
    "        y_true = results[split_name]['y_true']\n",
    "        \n",
    "        ax.hist(y_proba[y_true == 0], bins=30, alpha=0.6, label='No Diabetes', color='green')\n",
    "        ax.hist(y_proba[y_true == 1], bins=30, alpha=0.6, label='Diabetes', color='red')\n",
    "        ax.set_xlabel('Predicted Probability')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'{split_name.capitalize()} Prediction Distribution', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_path = os.path.join(output_dir, 'model_evaluation.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nVisualization saved to: {plot_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99326b47-d7a2-4f7a-be9a-f79a94defb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(results, output_dir):\n",
    "    \"\"\"Save metrics to a CSV file.\"\"\"\n",
    "    metrics_data = []\n",
    "    \n",
    "    for split_name in ['train', 'validation', 'test']:\n",
    "        metrics_data.append({\n",
    "            'Split': split_name,\n",
    "            'Accuracy': results[split_name]['accuracy'],\n",
    "            'Precision': results[split_name]['precision'],\n",
    "            'Recall': results[split_name]['recall'],\n",
    "            'F1-Score': results[split_name]['f1'],\n",
    "            'ROC-AUC': results[split_name]['roc_auc']\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    csv_path = os.path.join(output_dir, 'model_metrics.csv')\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Metrics saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10bfd287-3e26-4800-8006-073f27040a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/processed/permutation_000001\n",
      "============================================================\n",
      "Train set size: 60000\n",
      "Validation set size: 20000\n",
      "Test set size: 20000\n",
      "\n",
      "Categorical columns found: ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', 'smoking_status']\n",
      "Applying one-hot encoding...\n",
      "\n",
      "Features: ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'glucose_fasting', 'glucose_postprandial', 'insulin_level', 'hba1c', 'diabetes_risk_score', 'gender_Male', 'gender_Other', 'ethnicity_Black', 'ethnicity_Hispanic', 'ethnicity_Other', 'ethnicity_White', 'education_level_Highschool', 'education_level_No formal', 'education_level_Postgraduate', 'income_level_Low', 'income_level_Lower-Middle', 'income_level_Middle', 'income_level_Upper-Middle', 'employment_status_Retired', 'employment_status_Student', 'employment_status_Unemployed', 'smoking_status_Former', 'smoking_status_Never']\n",
      "Number of features: 41\n",
      "\n",
      "Standardizing features...\n",
      "\n",
      "Training Logistic Regression model...\n",
      "Training complete!\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "TRAIN SET:\n",
      "  Accuracy:  0.8588\n",
      "  Precision: 0.8732\n",
      "  Recall:    0.8960\n",
      "  F1-Score:  0.8845\n",
      "  ROC-AUC:   0.9346\n",
      "\n",
      "VALIDATION SET:\n",
      "  Accuracy:  0.8556\n",
      "  Precision: 0.8670\n",
      "  Recall:    0.8931\n",
      "  F1-Score:  0.8799\n",
      "  ROC-AUC:   0.9330\n",
      "\n",
      "TEST SET:\n",
      "  Accuracy:  0.8549\n",
      "  Precision: 0.8665\n",
      "  Recall:    0.8951\n",
      "  F1-Score:  0.8806\n",
      "  ROC-AUC:   0.9336\n",
      "\n",
      "Visualization saved to: ../results/LogisticRegression/model_evaluation.png\n",
      "Metrics saved to: ../results/LogisticRegression/model_metrics.csv\n",
      "\n",
      "============================================================\n",
      "Training and evaluation complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Train on the first permutation\n",
    "permutation_folder = '../data/processed/permutation_000001'\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(permutation_folder):\n",
    "    print(f\"Error: Folder '{permutation_folder}' not found!\")\n",
    "    print(\"Please specify the correct permutation folder path.\")\n",
    "else:\n",
    "    model, scaler, results = train_logistic_regression(\n",
    "        permutation_folder=permutation_folder,\n",
    "        target_column='diagnosed_diabetes', \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training and evaluation complete!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f59ab6-b14a-4e50-bb7d-cec7e159c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae54b3-6e8b-4352-af53-73c8589c024f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apc_jupyter_venv",
   "language": "python",
   "name": "apc_jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
