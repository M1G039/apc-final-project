{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification - Diabetes Stages\n\nThis notebook implements multiclass classification for diabetes stages with confidence estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.calibration import CalibratedClassifierCV\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/diabetes_multiclass.csv\")\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"\nStage distribution:\n{df[\"Stage\"].value_counts().sort_index()}\")\ndf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Outcome\", \"Stage\"], axis=1)\ny = df[\"Stage\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"Training set: {X_train.shape}\")\nprint(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, multi_class=\"multinomial\"),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42)\n}\n\nresults = {}\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_test_scaled)\n    y_proba = model.predict_proba(X_test_scaled)\n    \n    results[name] = {\n        \"model\": model,\n        \"accuracy\": accuracy_score(y_test, y_pred),\n        \"precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n        \"recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n        \"f1\": f1_score(y_test, y_pred, average=\"weighted\"),\n        \"y_pred\": y_pred,\n        \"y_proba\": y_proba\n    }\n\nprint(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame({name: {k: v for k, v in data.items() if k not in [\"model\", \"y_pred\", \"y_proba\"]} for name, data in results.items()}).T\nprint(\"\nModel Performance:\")\nprint(perf_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\nstage_labels = [\"Normal\", \"Pre-diabetes\", \"T2D Moderate\", \"T2D Severe\"]\n\nfor idx, (name, data) in enumerate(results.items()):\n    ax = axes[idx // 2, idx % 2]\n    cm = confusion_matrix(y_test, data[\"y_pred\"])\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, xticklabels=stage_labels, yticklabels=stage_labels)\n    ax.set_title(f\"{name}\nConfusion Matrix\")\n    ax.set_ylabel(\"True Label\")\n    ax.set_xlabel(\"Predicted Label\")\n    \nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda x: results[x][\"accuracy\"])\nbest_model = results[best_model_name][\"model\"]\nprint(f\"Best model: {best_model_name}\")\n\nproba = best_model.predict_proba(X_test_scaled)\nconfidence = np.max(proba, axis=1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(confidence, bins=30, edgecolor=\"black\")\nplt.xlabel(\"Confidence\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"{best_model_name}\nPrediction Confidence\")\n\nplt.subplot(1, 2, 2)\nfor stage in range(4):\n    mask = y_test == stage\n    plt.scatter(np.where(mask)[0], confidence[mask], label=stage_labels[stage], alpha=0.6)\nplt.xlabel(\"Sample Index\")\nplt.ylabel(\"Confidence\")\nplt.title(\"Confidence by True Stage\")\nplt.legend()\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confidence per class\navg_conf_per_class = []\nfor stage in range(4):\n    mask = y_test == stage\n    avg_conf_per_class.append(confidence[mask].mean())\n\nplt.figure(figsize=(10, 6))\nplt.bar(stage_labels, avg_conf_per_class, color=[\"#2ecc71\", \"#f39c12\", \"#e67e22\", \"#e74c3c\"])\nplt.ylabel(\"Average Confidence\")\nplt.title(f\"{best_model_name}\nAverage Confidence by Stage\")\nplt.ylim([0, 1])\nfor i, v in enumerate(avg_conf_per_class):\n    plt.text(i, v + 0.02, f\"{v:.3f}\", ha=\"center\")\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model = CalibratedClassifierCV(best_model, method=\"sigmoid\", cv=5)\ncalibrated_model.fit(X_train_scaled, y_train)\n\ny_proba_cal = calibrated_model.predict_proba(X_test_scaled)\nconfidence_cal = np.max(y_proba_cal, axis=1)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].hist(confidence, bins=30, alpha=0.7, label=\"Before Calibration\", edgecolor=\"black\")\naxes[0].set_xlabel(\"Confidence\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].set_title(\"Before Calibration\")\naxes[0].legend()\n\naxes[1].hist(confidence_cal, bins=30, alpha=0.7, label=\"After Calibration\", color=\"green\", edgecolor=\"black\")\naxes[1].set_xlabel(\"Confidence\")\naxes[1].set_ylabel(\"Frequency\")\naxes[1].set_title(\"After Calibration\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nIn this notebook, we:\n1. Trained multiple multiclass classification models\n2. Evaluated performance across all diabetes stages\n3. Implemented confidence estimation techniques\n4. Applied calibration for improved confidence estimates\n\nThe models can now predict diabetes stages with associated confidence levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}